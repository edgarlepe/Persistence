{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Users Using Topological Data Analysis\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this notebook we will be calculating persistence diagrams for all the\n",
    "subjects in the study, and then try to identify the users using the bottleneck\n",
    "distance of their respective persistence diagrams.\n",
    "\n",
    "## 2. Approach\n",
    "\n",
    "We will train a machine learning model to identify users based on the\n",
    "bottleneck distances of the persistance diagrams of their typing data and check\n",
    "its accuracy. Then we will introduce a new sample of typing data and see check\n",
    "how accurately it matches the new sample to a user.\n",
    "\n",
    "### 2.1. Setup\n",
    "\n",
    "First we load the typing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi                 as gd\n",
    "import pandas                as pd\n",
    "import matplotlib.pyplot     as plt\n",
    "import numpy                 as np\n",
    "import gudhi.representations as gdrep\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "strong_password_data_frame = pd.read_csv('data/DSL-StrongPasswordData.csv',\n",
    "                                   # declare type of 'subject' column\n",
    "                                   dtype = {'subject' : 'string'},\n",
    "                                   index_col = ['subject', 'sessionIndex', 'rep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did in the previous notebook, we seperate each subject's typing data\n",
    "and put it in an array of DataFrames where each index contains all the typing\n",
    "data for a specific user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjects_in_range(start, stop):\n",
    "    \"\"\"Returns a list of labels for subjects in the subject column.\n",
    "\n",
    "    :param start: integer between 2 and 57, inclusive\n",
    "    :param stop: integer between 2 and 57, inclusive. Should be greater than or\n",
    "                 equal to start.\n",
    "    :returns: list of zero-padded subject labels beginning with s{start} to s{stop}\n",
    "    \"\"\"\n",
    "    return [f's{i:03}' for i in range(start, 1 + stop) if i not in [6, 9, 14, 23, 45]]\n",
    "\n",
    "people = [strong_password_data_frame.loc[subject] for subject in subjects_in_range(2,57)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculating Persistence Diagrams for Training\n",
    "\n",
    "Now, we user the first six sessions to calculate three persistence diagrams for\n",
    "each user. We will only be using the first homology since it appears to be the\n",
    "best choice for identifying a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 1\n",
    "last_person = 57\n",
    "max_edge_length = 3.0\n",
    "max_dimension = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_for_person = []\n",
    "\n",
    "train_labels = []\n",
    "label_idx = 0\n",
    "\n",
    "for person, name in zip(people, subjects_in_range(2,last_person)):\n",
    "    diagrams = []\n",
    "    for n in range(3):\n",
    "        train_labels.append(label_idx)\n",
    "        points = person.loc[2*n + 1 : 2*(n+1)]\n",
    "        simplicial_complex = gd.RipsComplex(points = points.to_numpy(),\n",
    "                                            max_edge_length=max_edge_length)\n",
    "        simplex_tree = simplicial_complex.create_simplex_tree(max_dimension = max_dimension)\n",
    "        diagram = simplex_tree.persistence()\n",
    "        diagrams.append(simplex_tree.persistence_intervals_in_dimension(dimension))\n",
    "        \n",
    "    train_diagrams_for_person.append(diagrams)\n",
    "    label_idx = label_idx + 1\n",
    "    # print(f'Training diagrams for {name} complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculating Persistence Diagrams for Testing\n",
    "\n",
    "Similarly, we use the last two sessions to calculate a persistence diagram for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_diagrams_for_person = []\n",
    "test_labels = []\n",
    "label_idx = 0\n",
    "\n",
    "for person, name in zip(people, subjects_in_range(2,last_person)):\n",
    "    diagrams = []\n",
    "    test_labels.append(label_idx)\n",
    "    points = person.loc[7:8] # get ith session\n",
    "    simplicial_complex = gd.RipsComplex(points = points.to_numpy(),\n",
    "                                        max_edge_length=max_edge_length)\n",
    "    simplex_tree = simplicial_complex.create_simplex_tree(max_dimension = max_dimension)\n",
    "    diagram = simplex_tree.persistence()\n",
    "    diagrams.append(simplex_tree.persistence_intervals_in_dimension(dimension))\n",
    "    \n",
    "    test_diagrams_for_person.append(diagrams)\n",
    "    label_idx = label_idx + 1\n",
    "    # print(f'Test diagrams for {name} complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(train_diagrams_for_person).flatten()\n",
    "test_data = np.array(test_diagrams_for_person).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results and Analysis\n",
    "\n",
    "Using the Bottleneck distance, our machine learning model was able to correctly\n",
    "match typing data it had already seen to its user with about 50% accuracy.\n",
    "However, when we introduced new typing data, its accuracy dropped down to\n",
    "about 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                 (\"TDA\",       gd.representations.BottleneckDistance(0.001)),\n",
    "                 (\"Estimator\", KNeighborsClassifier(n_neighbors=2, metric=\"precomputed\"))\n",
    "])\n",
    "model = pipe.fit(training_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49019607843137253"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(training_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0196078431372549"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion and Future Work\n",
    "\n",
    "Our machine learning experience is very limited, so we may have been able to\n",
    "achieve better results by changing some paramaters. We were also limited by\n",
    "the amount of session data, our hardware, our time constraint, and other\n",
    "outside factors.\n",
    "\n",
    "There are other tools in Topological Data Analysis besides the Bottleneck\n",
    "distance that could led to better results. For example, the Persistence\n",
    "Landscape gave us 100% accuracy with typing data it had already seen and\n",
    "about 8% accuracy when shown new typing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"Scaler\",    gd.representations.DiagramScaler(scalers=[([0,1], MinMaxScaler())])),\n",
    "                 (\"TDA\",       gd.representations.BottleneckDistance(0.001)),\n",
    "                 (\"Estimator\", KNeighborsClassifier(n_neighbors=3, metric=\"precomputed\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param =    [\n",
    "            {\"Scaler__use\":         [True],\n",
    "             \"TDA\":                 [gd.representations.Landscape()], \n",
    "             \"TDA__resolution\":     [150],\n",
    "             \"TDA__num_landscapes\": [3],\n",
    "             \"Estimator\":           [RandomForestClassifier()]},\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipe, param, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(training_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'Scaler__use': True,\n",
       " 'TDA': Landscape(num_landscapes=3, resolution=150, sample_range=[nan, nan]),\n",
       " 'TDA__num_landscapes': 3,\n",
       " 'TDA__resolution': 150}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(training_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058823529411764705"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
